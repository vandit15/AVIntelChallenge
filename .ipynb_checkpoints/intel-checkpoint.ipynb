{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "W5nBDCSNmIoy",
    "outputId": "322fb718-fa86-4e93-9037-7f35b4b1edc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "4PkT2bj_qQd3",
    "outputId": "f2c94a86-2bac-4acd-da57-dbf4e0be7dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073750016 bytes == 0x58b96000 @  0x7f4f8f1632a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
     ]
    }
   ],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GIIHQIXpmyYi"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "# from tensorboardX import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SKNyjC1DqPHJ"
   },
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.img_name = self.image_frame.image_name\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.root_dir + '/' + self.img_name[idx])\n",
    "        if self.mode == 'train':\n",
    "            label = self.image_frame.iloc[idx].label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qHfpEU68rvQy"
   },
   "outputs": [],
   "source": [
    "'''Input the Training and Testing Data\n",
    "'''\n",
    "import cv2\n",
    "train_path = '/gdrive/My Drive/Analytics_scene_classification/train'\n",
    "\n",
    "train_dataset = SceneDataset(csv_file='/gdrive/My Drive/Analytics_scene_classification/train.csv',\n",
    "                                    root_dir=train_path, transform=transforms.Compose([\n",
    "                                               transforms.RandomHorizontalFlip(),\n",
    "#                                                transforms.RandomVerticalFlip(),\n",
    "#                                                transforms.RandomRotation(90),\n",
    "                                               transforms.Resize((224, 224)),\n",
    "                                               transforms.RandomRotation(30),\n",
    "                                               transforms.ToTensor()\n",
    "                                           ]), mode = 'train')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=12)\n",
    "test_dataset = SceneDataset(csv_file='/gdrive/My Drive/Analytics_scene_classification/test.csv', root_dir=train_path, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]), mode = 'val')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=12)\n",
    "\n",
    "validation_split = .15\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                           sampler=train_sampler,shuffle=False, num_workers=12)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                                sampler=valid_sampler, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "E36tTnNCuGN9",
    "outputId": "3626b6c2-39c5-411b-f328-c1558dd6f047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 14479, 'val': 2555}\n",
      "533 229 453 80\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {'train': len(train_dataset) - split, 'val': split}\n",
    "print (dataset_sizes)\n",
    "print (len(train_dataloader), len(test_dataloader), len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "B_yNromZjV1M",
    "outputId": "1eafccbb-0e4d-4aab-dcc1-6dd3de7969cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "kernel_size = (1,1)\n",
    "stride = (1,1)\n",
    "\n",
    "\"\"\" training functions\n",
    "\"\"\"\n",
    "model_conv = torchvision.models.densenet121(pretrained='imagenet')\n",
    "num_ftrs = model_conv.classifier.in_features\n",
    "maxm = 0\n",
    "for i, param in model_conv.named_parameters():\n",
    "    maxm = maxm + 1\n",
    "    if maxm < 182:\n",
    "      param.requires_grad = False\n",
    "print(maxm)\n",
    "model_conv.classifier = nn.Linear(num_ftrs, 6)\n",
    "model_conv = model_conv.cuda()\n",
    "# model_conv.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "\n",
    "## squeezenet\n",
    "# model_conv = torchvision.models.squeezenet1_1()\n",
    "# # for name, params in model_conv.named_children():\n",
    "# #     print(name)\n",
    "# '''\n",
    "# features\n",
    "# classifier\n",
    "# '''\n",
    "# ## How many In_channels are there for the conv layer\n",
    "# in_ftrs = model_conv.classifier[1].in_channels\n",
    "# ## How many Out_channels are there for the conv layer\n",
    "# out_ftrs = model_conv.classifier[1].out_channels\n",
    "# ## Converting a sequential layer to list of layers \n",
    "# features = list(model_conv.classifier.children())\n",
    "# ## Changing the conv layer to required dimension\n",
    "# features[1] = nn.Conv2d(in_ftrs, n_class, kernel_size,stride)\n",
    "# ## Changing the pooling layer as per the architecture output\n",
    "# features[3] = nn.AvgPool2d(13, stride=1)\n",
    "# ## Making a container to list all the layers\n",
    "# model_conv.classifier = nn.Sequential(*features)\n",
    "# ## Mentioning the number of out_put classes\n",
    "# model_conv.num_classes = n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Szym2HRau1Yf",
    "outputId": "c9d8bd35-757e-49bc-81e3-8108a18d36a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/453 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  5%|▌         | 24/453 [00:39<04:31,  1.58it/s]"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer_conv = optim.Adam(list(filter(lambda p: p.requires_grad, model_conv.parameters())), lr=5e-4)\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_conv,mode = 'min', patience=3, factor = 0.5)\n",
    " \n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup = False, alpha = 0.1):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            # get the inputs\n",
    "            for data in tqdm(dataloaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                if type(outputs) == tuple:\n",
    "                    outputs, _ = outputs\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = float(running_loss.cpu()) / dataset_sizes[phase]\n",
    "            epoch_acc = float(running_corrects.cpu()) / dataset_sizes[phase]\n",
    "            \n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                'phase', epoch_loss, epoch_acc))\n",
    "#             print (int(running_corrects.cpu()))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        scheduler.step(epoch_loss)\n",
    "        for param_group in optimizer.param_groups:\n",
    "          print(param_group['lr'])\n",
    "    \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "  \n",
    "\n",
    "model_conv = train_model(model_conv, {'train':train_loader, 'val':val_loader}, dataset_sizes, criterion, optimizer_conv, exp_lr_scheduler, True,\n",
    "                     num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "DLt8CIAW13F2",
    "outputId": "4c95574b-5a8d-4f12-f086-c65d60277ebc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:33<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, dataloaders, optimizer, use_gpu):\n",
    "    model.train(False)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataloaders):\n",
    "        inputs, labels_ = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        predictions.append(preds)\n",
    "        labels.append(labels_)\n",
    "\n",
    "    return predictions, labels\n",
    "  \n",
    "predictions, labels = test_model(model_conv, val_loader, optimizer_conv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XtxoD0t1vnxT"
   },
   "outputs": [],
   "source": [
    "###saving Model\n",
    "\n",
    "PATH = '/gdrive/My Drive/Analytics_scene_classification/densenet121_half_pretrained_5e-4.pth.tar'\n",
    "torch.save(model_conv.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wJfW-PKPe9fG"
   },
   "outputs": [],
   "source": [
    "predictions, labels = torch.cat(predictions), torch.cat(labels)\n",
    "predictions, labels = np.array(predictions.cpu()), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MInmMhyhgryl",
    "outputId": "6d521005-0030-4020-f9ac-79bde646714a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       386\n",
      "           1       0.98      0.99      0.98       401\n",
      "           2       0.89      0.93      0.91       402\n",
      "           3       0.94      0.91      0.92       466\n",
      "           4       0.98      0.97      0.98       404\n",
      "           5       0.94      0.96      0.95       496\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2555\n",
      "   macro avg       0.94      0.94      0.94      2555\n",
      "weighted avg       0.94      0.94      0.94      2555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print (sklearn.metrics.classification_report(predictions, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "YQr-HPyhC-ZC",
    "outputId": "72c19817-70f4-470e-faef-9b591237b317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          col1      col2      col3      col4\n",
      "col1  1.000000  0.979773  0.972429  0.989718\n",
      "col2  0.979773  1.000000  0.972400  0.983652\n",
      "col3  0.972429  0.972400  1.000000  0.976085\n",
      "col4  0.989718  0.983652  0.976085  1.000000\n"
     ]
    }
   ],
   "source": [
    "densenet = pd.read_csv('densenet121.csv')['label']\n",
    "resnet101 = pd.read_csv('resnet101.csv')['label']\n",
    "resnet50 = pd.read_csv('resnet50.csv')['label']\n",
    "labels = pd.read_csv('/gdrive/My Drive/Analytics_scene_classification/train.csv')['label']\n",
    "df = pd.DataFrame({'col1': densenet, 'col2': resnet101, 'col3': resnet50, 'col4': labels})\n",
    "print (df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "lzy0xRklg5wT",
    "outputId": "3b41cc08-5b95-4570-b63c-96cf060a98eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3  col4\n",
       "0     0     0     0     0\n",
       "1     4     4     4     4\n",
       "2     5     5     5     5\n",
       "3     0     0     0     0\n",
       "4     4     4     4     4"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "wbewSx3zSM0_",
    "outputId": "ea93eebc-5f18-4f28-f638-7080b57f69fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13627, 4) (3407, 4)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "train_data, test_data = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=123, shuffle=False)\n",
    "print (train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uGLrDehKSuQa"
   },
   "outputs": [],
   "source": [
    "X_train = train_data[['col1', 'col2', 'col3']].values\n",
    "y_train = train_data['col4'].values\n",
    "\n",
    "X_test = test_data[['col1', 'col2', 'col3']].values\n",
    "y_test = test_data['col4'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "e3iDYVuyUFKj",
    "outputId": "7882f4ba-26db-4e5b-98ae-3bd24a690f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13627, 3) (13627,) (3407, 3) (3407,)\n",
      "[[0 0 0]\n",
      " [4 4 4]\n",
      " [5 5 5]\n",
      " ...\n",
      " [5 5 5]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "vg-CHgKDUYdP",
    "outputId": "29cc6e8b-cdc1-432d-812d-0464627365bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                          multi_class='multinomial', max_iter=1000, verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "BtU58zjbU3aI",
    "outputId": "1c1a13c2-c8a9-4f94-c19f-203695f65ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906075726445553\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print (accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vCeaDwriVCg4"
   },
   "outputs": [],
   "source": [
    "densenet_test = pd.read_csv('densenet121_test.csv')['label']\n",
    "resnet101_test = pd.read_csv('resnet101_test.csv')['label']\n",
    "resnet50_test = pd.read_csv('resnet50_test.csv')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xrxZUKt3hb5B"
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'col1': densenet, 'col2': resnet101, 'col3': resnet50}).values\n",
    "predictions = clf.predict(df_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "comp.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
